{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 transformers==4.45.0 datasets==2.18.0 librosa==0.11.0 scikit-learn==1.7.2 pandas==2.2.3 numpy==2.1.2 matplotlib==3.9.2 seaborn==0.13.2 opencv-python==4.10.0.84 tqdm==4.67.1 soundfile==0.13.0 scipy==1.13.0 pydub==0.25.1 Pillow==11.0.0 tensorboard==2.17.0 wget==3.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T19:02:40.065292Z","iopub.execute_input":"2025-11-20T19:02:40.065619Z","iopub.status.idle":"2025-11-20T19:02:40.085973Z","shell.execute_reply.started":"2025-11-20T19:02:40.065596Z","shell.execute_reply":"2025-11-20T19:02:40.084820Z"}},"outputs":[{"name":"stdout","text":"\n     \n\n Collecting torch==2.3.1 \n\n   Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB) \n\n Collecting torchvision==0.18.1 \n\n   Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB) \n\n Collecting torchaudio==2.3.1 \n\n   Downloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB) \n\n Collecting transformers==4.45.0 \n\n   Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB) \n\n      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.4/44.4 kB 1.7 MB/s eta 0:00:00 \n\n Collecting datasets==2.18.0 \n\n   Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB) \n\n Requirement already satisfied: librosa==0.11.0 in /usr/local/lib/python3.12/dist-packages (0.11.0) \n\n Collecting scikit-learn==1.7.2 \n\n   Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB) \n\n Collecting pandas==2.2.3 \n\n   Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB) \n\n      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.9/89.9 kB 3.9 MB/s eta 0:00:00 \n\n Collecting numpy==2.1.2 \n\n   Downloading numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB) \n\n      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.9/60.9 kB 3.7 MB/s eta 0:00:00 \n\n Collecting matplotlib==3.9.2 \n\n   Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB) \n\n Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.12/dist-packages (0.13.2) \n\n Collecting opencv-python==4.10.0.84 \n\n   Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB) \n\n Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (4.67.1) \n\n Collecting soundfile==0.13.0 \n\n   Downloading soundfile-0.13.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB) \n\n Collecting scipy==1.13.0 \n\n   Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB) \n\n      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 2.7 MB/s eta 0:00:00 \n\n Requirement already satisfied: pydub==0.25.1 in /usr/local/lib/python3.12/dist-packages (0.25.1) \n\n Collecting Pillow==11.0.0 \n\n   Downloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB) \n\n Collecting tensorboard==2.17.0 \n\n   Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB) \n\n Collecting wget==3.2 \n\n   Downloading wget-3.2.zip (10 kB) \n\n   Preparing metadata (setup.py) ... done \n\n Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.20.0) \n\n Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (4.15.0) \n\n Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (1.13.3) \n\n Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.5) \n\n Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (3.1.6) \n\n Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.1) (2025.3.0) \n\n Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1) \n\n   Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB) \n\n Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1) \n\n   Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB) \n\n Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1) \n\n   Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB) \n\n Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1) \n\n   Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB) \n\n Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1) \n\n   Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB) \n\n Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1) \n\n   Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB) \n\n Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1) \n\n   Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB) \n\n Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1) \n\n   Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB) \n\n Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1) \n\n   Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB) \n\n Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1) \n\n   Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB) \n\n Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1) \n\n   Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB) \n\n Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.0) (0.36.0) \n\n Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.0) (25.0) \n\n Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.0) (6.0.3) \n\n Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.0) (2024.11.6) \n\n Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.0) (2.32.4) \n\n Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.0) \n\n   Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB) \n\n Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.0) (0.6.2) \n\n Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0) (18.1.0) \n\n Collecting pyarrow-hotfix (from datasets==2.18.0) \n\n   Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB) \n\n Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0) (0.3.8) \n\n Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0) (3.6.0) \n\n Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0) (0.70.16) \n\n Collecting fsspec (from torch==2.3.1) \n\n   Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB) \n\n Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0) (3.13.2) \n\n Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (3.1.0) \n\n Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (0.60.0) \n\n Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.5.2) \n\n Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (4.4.2) \n\n Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.8.2) \n\n Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.0.0) \n\n Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (0.4) \n\n Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.1.2) \n\n Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (3.6.0) \n\n Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2.9.0.post0) \n\n Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2) \n\n Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2) \n\n Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (1.3.3) \n\n Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (0.12.1) \n\n Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (4.60.1) \n\n Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (1.4.9) \n\n Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.9.2) (3.2.5) \n\n Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile==0.13.0) (2.0.0) \n\n Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) (1.4.0) \n\n Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) (1.76.0) \n\n Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) (3.10) \n\n Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard==2.17.0) \n\n   Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes) \n\n Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) (75.2.0) \n\n Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) (1.17.0) \n\n Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) \n\n (0.7.2) \n\n Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard==2.17.0) (3.1.3) \n\n Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5 \n\n 107->torch==2.3.1) (12.6.85) \n\n Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile==0.13.0) (2.23) \n\n Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (2.6.1) \n\n Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (1.4.0) \n\n Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (25.4.0) \n\n Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (1.8.0) \n\n Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (6.7.0) \n\n Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (0.4.1) \n\n Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0) (1.22.0) \n\n Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23 \n\n 2->transformers==4.45.0) (1.2.0) \n\n Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa==0.11.0) \n\n (0.43.0) \n\n INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a \n\n while. \n\n Collecting numba>=0.51.0 (from librosa==0.11.0) \n\n   Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB) \n\n Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa==0.11.0) \n\n   Downloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB) \n\n Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa==0.11.0) (4.5.0) \n\n Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.0) \n\n (3.4.4) \n\n Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.0) (3.11) \n\n Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.0) (2.5.0) \n\n Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.0) (2025 \n\n 10.5) \n\n Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard==2.17.0) (3 \n\n 0.3) \n\n Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.1) (1.3.0) \n\n Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 779.1/779.1 MB 1.2 MB/s eta 0:00:00 \n\n Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl (7.0 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 35.1 MB/s eta 0:00:00 \n\n Downloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl (3.4 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 60.6 MB/s eta 0:00:00 \n\n Downloading transformers-4.45.0-py3-none-any.whl (9.9 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 100.9 MB/s eta 0:00:00 \n\n Downloading datasets-2.18.0-py3-none-any.whl (510 kB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 31.7 MB/s eta 0:00:00 \n\n Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.5/9.5 MB 99.4 MB/s eta 0:00:00 \n\n Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.7/12.7 MB 94.1 MB/s eta 0:00:00 \n\n Downloading numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 81.5 MB/s eta 0:00:00 \n\n Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 67.8 MB/s eta 0:00:00 \n\n Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.5/62.5 MB 11.0 MB/s eta 0:00:00 \n\n Downloading soundfile-0.13.0-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 28.8 MB/s eta 0:00:00 \n\n Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.2/38.2 MB 13.9 MB/s eta 0:00:00 \n\n Downloading pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 36.4 MB/s eta 0:00:00 \n\n Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 43.2 MB/s eta 0:00:00 \n\n Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 4.2 MB/s eta 0:00:00 \n\n Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 73.1 MB/s eta 0:00:00 \n\n Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 64.0 MB/s eta 0:00:00 \n\n Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 27.3 MB/s eta 0:00:00 \n\n Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 877.3 kB/s eta 0:00:00 \n\n Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 8.1 MB/s eta 0:00:00 \n\n Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 13.6 MB/s eta 0:00:00 \n\n Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 8.4 MB/s eta 0:00:00 \n\n Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 5.5 MB/s eta 0:00:00 \n\n Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 6.8 MB/s eta 0:00:00 \n\n Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 8.3 MB/s eta 0:00:00 \n\n Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.9/170.9 kB 15.0 MB/s eta 0:00:00 \n\n Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 98.5 MB/s eta 0:00:00 \n\n Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.9/294.9 kB 24.1 MB/s eta 0:00:00 \n\n Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 111.3 MB/s eta 0:00:00 \n\n Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB) \n\n Downloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB) \n\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 13.9 MB/s eta 0:00:00 \n\n Building wheels for collected packages: wget \n\n   Building wheel for wget (setup.py) ... done \n\n   Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=3b48b4594b82e65296f2160e1441f11211f63e79b7267c87a21be93fcc36b801 \n\n   Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9 \n\n Successfully built wget \n\n Installing collected packages: wget, pyarrow-hotfix, protobuf, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, \n\n nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, \n\n numpy, llvmlite, fsspec, tensorboard, soundfile, scipy, pandas, opencv-python, nvidia-cusolver-cu12, nvidia-cudnn-cu12, numba, torch, \n\n tokenizers, scikit-learn, matplotlib, transformers, torchvision, torchaudio, datasets \n\n   Attempting uninstall: protobuf \n\n     Found existing installation: protobuf 5.29.5 \n\n     Uninstalling protobuf-5.29.5: \n\n       Successfully uninstalled protobuf-5.29.5 \n\n   Attempting uninstall: Pillow \n\n     Found existing installation: pillow 11.3.0 \n\n     Uninstalling pillow-11.3.0: \n\n       Successfully uninstalled pillow-11.3.0 \n\n   Attempting uninstall: nvidia-nvtx-cu12 \n\n     Found existing installation: nvidia-nvtx-cu12 12.6.77 \n\n     Uninstalling nvidia-nvtx-cu12-12.6.77: \n\n       Successfully uninstalled nvidia-nvtx-cu12-12.6.77 \n\n   Attempting uninstall: nvidia-nccl-cu12 \n\n     Found existing installation: nvidia-nccl-cu12 2.27.3 \n\n     Uninstalling nvidia-nccl-cu12-2.27.3: \n\n       Successfully uninstalled nvidia-nccl-cu12-2.27.3 \n\n   Attempting uninstall: nvidia-cusparse-cu12 \n\n     Found existing installation: nvidia-cusparse-cu12 12.5.4.2 \n\n     Uninstalling nvidia-cusparse-cu12-12.5.4.2: \n\n       Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2 \n\n   Attempting uninstall: nvidia-curand-cu12 \n\n     Found existing installation: nvidia-curand-cu12 10.3.7.77 \n\n     Uninstalling nvidia-curand-cu12-10.3.7.77: \n\n       Successfully uninstalled nvidia-curand-cu12-10.3.7.77 \n\n   Attempting uninstall: nvidia-cufft-cu12 \n\n     Found existing installation: nvidia-cufft-cu12 11.3.0.4 \n\n     Uninstalling nvidia-cufft-cu12-11.3.0.4: \n\n       Successfully uninstalled nvidia-cufft-cu12-11.3.0.4 \n\n   Attempting uninstall: nvidia-cuda-runtime-cu12 \n\n     Found existing installation: nvidia-cuda-runtime-cu12 12.6.77 \n\n     Uninstalling nvidia-cuda-runtime-cu12-12.6.77: \n\n       Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77 \n\n   Attempting uninstall: nvidia-cuda-nvrtc-cu12 \n\n     Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77 \n\n     Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77: \n\n       Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77 \n\n   Attempting uninstall: nvidia-cuda-cupti-cu12 \n\n     Found existing installation: nvidia-cuda-cupti-cu12 12.6.80 \n\n     Uninstalling nvidia-cuda-cupti-cu12-12.6.80: \n\n       Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80 \n\n   Attempting uninstall: nvidia-cublas-cu12 \n\n     Found existing installation: nvidia-cublas-cu12 12.6.4.1 \n\n     Uninstalling nvidia-cublas-cu12-12.6.4.1: \n\n       Successfully uninstalled nvidia-cublas-cu12-12.6.4.1 \n\n   Attempting uninstall: numpy \n\n     Found existing installation: numpy 2.0.2 \n\n     Uninstalling numpy-2.0.2: \n\n       Successfully uninstalled numpy-2.0.2 \n\n   Attempting uninstall: llvmlite \n\n     Found existing installation: llvmlite 0.43.0 \n\n     Uninstalling llvmlite-0.43.0: \n\n       Successfully uninstalled llvmlite-0.43.0 \n\n   Attempting uninstall: fsspec \n\n     Found existing installation: fsspec 2025.3.0 \n\n     Uninstalling fsspec-2025.3.0: \n\n       Successfully uninstalled fsspec-2025.3.0 \n\n   Attempting uninstall: tensorboard \n\n     Found existing installation: tensorboard 2.19.0 \n\n     Uninstalling tensorboard-2.19.0: \n\n       Successfully uninstalled tensorboard-2.19.0 \n\n   Attempting uninstall: soundfile \n\n     Found existing installation: soundfile 0.13.1 \n\n     Uninstalling soundfile-0.13.1: \n\n       Successfully uninstalled soundfile-0.13.1 \n\n   Attempting uninstall: scipy \n\n     Found existing installation: scipy 1.16.3 \n\n     Uninstalling scipy-1.16.3: \n\n       Successfully uninstalled scipy-1.16.3 \n\n   Attempting uninstall: pandas \n\n     Found existing installation: pandas 2.2.2 \n\n     Uninstalling pandas-2.2.2: \n\n       Successfully uninstalled pandas-2.2.2 \n\n   Attempting uninstall: opencv-python \n\n     Found existing installation: opencv-python 4.12.0.88 \n\n     Uninstalling opencv-python-4.12.0.88: \n\n       Successfully uninstalled opencv-python-4.12.0.88 \n\n   Attempting uninstall: nvidia-cusolver-cu12 \n\n     Found existing installation: nvidia-cusolver-cu12 11.7.1.2 \n\n     Uninstalling nvidia-cusolver-cu12-11.7.1.2: \n\n       Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2 \n\n   Attempting uninstall: nvidia-cudnn-cu12 \n\n     Found existing installation: nvidia-cudnn-cu12 9.10.2.21 \n\n     Uninstalling nvidia-cudnn-cu12-9.10.2.21: \n\n       Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21 \n\n   Attempting uninstall: numba \n\n     Found existing installation: numba 0.60.0 \n\n     Uninstalling numba-0.60.0: \n\n       Successfully uninstalled numba-0.60.0 \n\n   Attempting uninstall: torch \n\n     Found existing installation: torch 2.8.0+cu126 \n\n     Uninstalling torch-2.8.0+cu126: \n\n       Successfully uninstalled torch-2.8.0+cu126 \n\n   Attempting uninstall: tokenizers \n\n     Found existing installation: tokenizers 0.22.1 \n\n     Uninstalling tokenizers-0.22.1: \n\n       Successfully uninstalled tokenizers-0.22.1 \n\n   Attempting uninstall: scikit-learn \n\n     Found existing installation: scikit-learn 1.6.1 \n\n     Uninstalling scikit-learn-1.6.1: \n\n       Successfully uninstalled scikit-learn-1.6.1 \n\n   Attempting uninstall: matplotlib \n\n     Found existing installation: matplotlib 3.10.0 \n\n     Uninstalling matplotlib-3.10.0: \n\n       Successfully uninstalled matplotlib-3.10.0 \n\n   Attempting uninstall: transformers \n\n     Found existing installation: transformers 4.57.1 \n\n     Uninstalling transformers-4.57.1: \n\n       Successfully uninstalled transformers-4.57.1 \n\n   Attempting uninstall: torchvision \n\n     Found existing installation: torchvision 0.23.0+cu126 \n\n     Uninstalling torchvision-0.23.0+cu126: \n\n       Successfully uninstalled torchvision-0.23.0+cu126 \n\n   Attempting uninstall: torchaudio \n\n     Found existing installation: torchaudio 2.8.0+cu126 \n\n     Uninstalling torchaudio-2.8.0+cu126: \n\n       Successfully uninstalled torchaudio-2.8.0+cu126 \n\n   Attempting uninstall: datasets \n\n     Found existing installation: datasets 4.0.0 \n\n     Uninstalling datasets-4.0.0: \n\n       Successfully uninstalled datasets-4.0.0\n    \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport tarfile\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nimport torchaudio\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Checking GPU...\")\nprint(f\"GPU available: {torch.cuda.is_available()}\")\nprint(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Install required libraries\n!pip install -q transformers torchaudio torchvision opencv-python pillow seaborn librosa\n\n# Check if dataset is already downloaded\nif not os.path.exists(\"MELD_Raw\"):\n    print(\"Dataset not found. Downloading...\")\n\n    # Download raw MELD archive\n    if not os.path.exists(\"MELD.Raw.tar.gz\"):\n        !wget -q https://web.eecs.umich.edu/~mihalcea/downloads/MELD.Raw.tar.gz\n\n    # Download CSV files\n    if not os.path.exists(\"train_sent_emo.csv\"):\n        !wget -q https://raw.githubusercontent.com/declare-lab/MELD/master/data/MELD/train_sent_emo.csv\n    if not os.path.exists(\"dev_sent_emo.csv\"):\n        !wget -q https://raw.githubusercontent.com/declare-lab/MELD/master/data/MELD/dev_sent_emo.csv\n    if not os.path.exists(\"test_sent_emo.csv\"):\n        !wget -q https://raw.githubusercontent.com/declare-lab/MELD/master/data/MELD/test_sent_emo.csv\n\n    # Extract only if not yet extracted\n    print(\"Extracting MELD.Raw.tar.gz...\")\n    with tarfile.open('MELD.Raw.tar.gz', 'r:gz') as tar:\n        tar.extractall('MELD_Raw')\n\nelse:\n    print(\"Dataset already exists. Skipping download and extraction.\")\n\n\nwith tarfile.open('MELD.Raw.tar.gz.1', 'r:gz') as tar:\n    tar.extractall('MELD_Raw')\n\ntrain_df = pd.read_csv('train_sent_emo.csv')\ndev_df = pd.read_csv('dev_sent_emo.csv')\ntest_df = pd.read_csv('test_sent_emo.csv')\n\nemotion_labels = {'neutral': 0, 'joy': 1, 'surprise': 2, 'sadness': 3, 'fear': 4, 'disgust': 5, 'anger': 6}\nsentiment_labels = {'neutral': 0, 'positive': 1, 'negative': 2}\n\nclass MELDDataset(Dataset):\n    def __init__(self, dataframe, base_path, modality='all', max_length=128, sr=22050, max_frames=75):\n        self.dataframe = dataframe\n        self.base_path = base_path\n        self.modality = modality\n        self.max_length = max_length\n        self.sr = sr\n        self.max_frames = max_frames\n        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def load_audio(self, dialogue_id, utterance_id):\n        audio_path = f\"{self.base_path}/train_splits/dia{dialogue_id}_utt{utterance_id}.wav\"\n        if not os.path.exists(audio_path):\n            audio_path = audio_path.replace(\"train_splits\", \"dev_splits_complete\")\n        if not os.path.exists(audio_path):\n            audio_path = audio_path.replace(\"dev_splits_complete\", \"test_splits_complete\")\n\n        try:\n            waveform, sample_rate = torchaudio.load(audio_path)\n            if sample_rate != self.sr:\n                waveform = torchaudio.transforms.Resample(sample_rate, self.sr)(waveform)\n            if waveform.shape[0] > 1:\n                waveform = torch.mean(waveform, dim=0, keepdim=True)\n            if waveform.shape[1] < self.sr * 3:\n                padding = self.sr * 3 - waveform.shape[1]\n                waveform = torch.nn.functional.pad(waveform, (0, padding))\n            else:\n                waveform = waveform[:, :self.sr * 3]\n            return waveform.squeeze(0)\n        except:\n            return torch.zeros(self.sr * 3)\n\n    def load_video_frames(self, dialogue_id, utterance_id):\n        video_path = f\"{self.base_path}/train_splits/dia{dialogue_id}_utt{utterance_id}.mp4\"\n        if not os.path.exists(video_path):\n            video_path = video_path.replace(\"train_splits\", \"dev_splits_complete\")\n        if not os.path.exists(video_path):\n            video_path = video_path.replace(\"dev_splits_complete\", \"test_splits_complete\")\n\n        frames = []\n        try:\n            cap = cv2.VideoCapture(video_path)\n            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n            if frame_count > 0:\n                indices = np.linspace(0, frame_count-1, min(self.max_frames, frame_count), dtype=int)\n                for i in range(max(indices) + 1):\n                    ret, frame = cap.read()\n                    if not ret:\n                        break\n                    if i in indices:\n                        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                        frame = cv2.resize(frame, (224, 224))\n                        frame = torch.tensor(frame).permute(2, 0, 1).float() / 255.0\n                        frames.append(frame)\n            cap.release()\n        except:\n            pass\n\n        if len(frames) == 0:\n            frames = [torch.zeros(3, 224, 224) for _ in range(self.max_frames)]\n\n        if len(frames) < self.max_frames:\n            padding = [torch.zeros(3, 224, 224) for _ in range(self.max_frames - len(frames))]\n            frames.extend(padding)\n        else:\n            frames = frames[:self.max_frames]\n\n        return torch.stack(frames)\n\n    def process_text(self, text):\n        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_length,\n                               padding='max_length', truncation=True)\n        return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        dialogue_id = row['Dialogue_ID']\n        utterance_id = row['Utterance_ID']\n        text = row['Utterance']\n        emotion = emotion_labels.get(row['Emotion'].lower(), 0)\n\n        text_input, attention_mask = self.process_text(text)\n\n        if self.modality in ['text', 'all', 'text_audio', 'text_video']:\n            audio = self.load_audio(dialogue_id, utterance_id)\n        else:\n            audio = torch.zeros(self.sr * 3)\n\n        if self.modality in ['video', 'all', 'text_video', 'audio_video']:\n            video_frames = self.load_video_frames(dialogue_id, utterance_id)\n        else:\n            video_frames = torch.zeros(self.max_frames, 3, 224, 224)\n\n        if self.modality == 'text':\n            return text_input, attention_mask, emotion\n        elif self.modality == 'audio':\n            return audio, emotion\n        elif self.modality == 'video':\n            return video_frames, emotion\n        elif self.modality == 'text_audio':\n            return text_input, attention_mask, audio, emotion\n        elif self.modality == 'text_video':\n            return text_input, attention_mask, video_frames, emotion\n        elif self.modality == 'audio_video':\n            return audio, video_frames, emotion\n        else:\n            return text_input, attention_mask, audio, video_frames, emotion\n\nclass TextModel(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.1)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        return self.classifier(pooled_output)\n\nclass AudioModel(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv1d(1, 16, kernel_size=64, stride=2, padding=32),\n            nn.ReLU(),\n            nn.MaxPool1d(8),\n            nn.Conv1d(16, 32, kernel_size=32, stride=2, padding=16),\n            nn.ReLU(),\n            nn.MaxPool1d(8),\n            nn.Conv1d(32, 64, kernel_size=16, stride=2, padding=8),\n            nn.ReLU(),\n            nn.MaxPool1d(8),\n            nn.AdaptiveAvgPool1d(1)\n        )\n        self.classifier = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        if x.dim() == 1:\n            x = x.unsqueeze(0)\n        x = x.unsqueeze(1)\n        x = self.cnn(x)\n        x = x.squeeze(-1)\n        return self.classifier(x)\n\nclass VideoModel(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.cnn = models.resnet18(pretrained=True)\n        self.cnn.fc = nn.Identity()\n        self.lstm = nn.LSTM(512, 256, batch_first=True, bidirectional=True)\n        self.classifier = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        batch_size, num_frames, C, H, W = x.shape\n        x = x.view(batch_size * num_frames, C, H, W)\n        features = self.cnn(x)\n        features = features.view(batch_size, num_frames, -1)\n        lstm_out, _ = self.lstm(features)\n        pooled = torch.mean(lstm_out, dim=1)\n        return self.classifier(pooled)\n\nclass MultimodalFusionModel(nn.Module):\n    def __init__(self, fusion_type='all', num_classes=7):\n        super().__init__()\n        self.fusion_type = fusion_type\n        self.text_model = TextModel(num_classes)\n        self.audio_model = AudioModel(num_classes)\n        self.video_model = VideoModel(num_classes)\n\n        input_size = 0\n        if fusion_type in ['all', 'text_audio', 'text_video']:\n            input_size += 768 # BERT hidden size\n        if fusion_type in ['all', 'text_audio', 'audio_video']:\n            input_size += 64 # Audio CNN output size\n        if fusion_type in ['all', 'text_video', 'audio_video']:\n            input_size += 512 # Video LSTM output size\n\n        self.fusion_classifier = nn.Linear(input_size, num_classes)\n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, text_input=None, attention_mask=None, audio_input=None, video_input=None):\n        features = []\n\n        if self.fusion_type in ['all', 'text_audio', 'text_video'] and text_input is not None:\n            text_features = self.text_model.bert(input_ids=text_input, attention_mask=attention_mask).pooler_output\n            features.append(text_features)\n\n        if self.fusion_type in ['all', 'text_audio', 'audio_video'] and audio_input is not None:\n            if audio_input.dim() == 1:\n                audio_input = audio_input.unsqueeze(0)\n            audio_input = audio_input.unsqueeze(1)\n            audio_features = self.audio_model.cnn(audio_input)\n            audio_features = audio_features.squeeze(-1) # Squeeze the last dimension to make it 2D\n            features.append(audio_features)\n\n        if self.fusion_type in ['all', 'text_video', 'audio_video'] and video_input is not None:\n            batch_size, num_frames, C, H, W = video_input.shape\n            video_flat = video_input.view(batch_size * num_frames, C, H, W)\n            video_cnn_features = self.video_model.cnn(video_flat)\n            video_cnn_features = video_cnn_features.view(batch_size, num_frames, -1)\n            lstm_out, _ = self.video_model.lstm(video_cnn_features)\n            video_features = torch.mean(lstm_out, dim=1)\n            features.append(video_features)\n\n        fused_features = torch.cat(features, dim=1)\n        fused_features = self.dropout(fused_features)\n        return self.fusion_classifier(fused_features)\n\ndef train_model(modality='all', epochs=2):\n    train_dataset = MELDDataset(train_df, 'MELD_Raw', modality=modality)\n    dev_dataset = MELDDataset(dev_df, 'MELD_Raw', modality=modality)\n\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    dev_loader = DataLoader(dev_dataset, batch_size=8, shuffle=False)\n\n    if modality == 'text':\n        model = TextModel().to(device)\n    elif modality == 'audio':\n        model = AudioModel().to(device)\n    elif modality == 'video':\n        model = VideoModel().to(device)\n    else:\n        model = MultimodalFusionModel(fusion_type=modality).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n\n    train_losses = []\n    val_accuracies = []\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n\n        for batch in progress_bar:\n            if modality == 'text':\n                inputs, masks, labels = batch\n                inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(inputs, masks)\n            elif modality == 'audio':\n                inputs, labels = batch\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(inputs)\n            elif modality == 'video':\n                inputs, labels = batch\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(inputs)\n            elif modality == 'text_audio':\n                text_inputs, masks, audio_inputs, labels = batch\n                text_inputs, masks = text_inputs.to(device), masks.to(device)\n                audio_inputs, labels = audio_inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(text_input=text_inputs, attention_mask=masks, audio_input=audio_inputs)\n            elif modality == 'text_video':\n                text_inputs, masks, video_inputs, labels = batch\n                text_inputs, masks = text_inputs.to(device), masks.to(device)\n                video_inputs, labels = video_inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(text_input=text_inputs, attention_mask=masks, video_input=video_inputs)\n            elif modality == 'audio_video':\n                audio_inputs, video_inputs, labels = batch\n                audio_inputs = audio_inputs.to(device)\n                video_inputs, labels = video_inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(audio_input=audio_inputs, video_input=video_inputs)\n            else:\n                text_inputs, masks, audio_inputs, video_inputs, labels = batch\n                text_inputs, masks = text_inputs.to(device), masks.to(device)\n                audio_inputs = audio_inputs.to(device)\n                video_inputs, labels = video_inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(text_input=text_inputs, attention_mask=masks,\n                              audio_input=audio_inputs, video_input=video_inputs)\n\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            total_loss += loss.item()\n            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n        scheduler.step()\n        avg_loss = total_loss / len(train_loader)\n        train_losses.append(avg_loss)\n\n        val_acc = evaluate_model(model, dev_loader, modality, device)\n        val_accuracies.append(val_acc)\n\n        print(f'Epoch {epoch+1}: Loss = {avg_loss:.4f}, Val Acc = {val_acc:.4f}')\n\n    torch.save(model.state_dict(), f'model_{modality}.pth')\n\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses)\n    plt.title(f'Training Loss - {modality}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(val_accuracies)\n    plt.title(f'Validation Accuracy - {modality}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.savefig(f'training_plots_{modality}.png')\n    plt.show()\n\n    return model, train_losses, val_accuracies\n\ndef evaluate_model(model, data_loader, modality, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            if modality == 'text':\n                inputs, masks, labels = batch\n                inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n                outputs = model(inputs, masks)\n            elif modality == 'audio':\n                inputs, labels = batch\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n            elif modality == 'video':\n                inputs, labels = batch\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n            elif modality == 'text_audio':\n                text_inputs, masks, audio_inputs, labels = batch\n                text_inputs, masks = text_inputs.to(device), masks.to(device)\n                audio_inputs, labels = audio_inputs.to(device), labels.to(device)\n                outputs = model(text_input=text_inputs, attention_mask=masks, audio_input=audio_inputs)\n            elif modality == 'text_video':\n                text_inputs, masks, video_inputs, labels = batch\n                text_inputs, masks = text_inputs.to(device), masks.to(device)\n                video_inputs, labels = video_inputs.to(device), labels.to(device)\n                outputs = model(text_input=text_inputs, attention_mask=masks, video_input=video_inputs)\n            elif modality == 'audio_video':\n                audio_inputs, video_inputs, labels = batch\n                audio_inputs = audio_inputs.to(device)\n                video_inputs, labels = video_inputs.to(device), labels.to(device)\n                outputs = model(audio_input=audio_inputs, video_input=video_inputs)\n            else:\n                text_inputs, masks, audio_inputs, video_inputs, labels = batch\n                text_inputs, masks = text_inputs.to(device), masks.to(device)\n                audio_inputs = audio_inputs.to(device)\n                video_inputs, labels = video_inputs.to(device), labels.to(device)\n                outputs = model(text_input=text_inputs, attention_mask=masks,\n                              audio_input=audio_inputs, video_input=video_inputs)\n\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    print(f'Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')\n    print(classification_report(all_labels, all_preds,\n                              target_names=list(emotion_labels.keys())))\n    return accuracy\n\nmodalities = ['text', 'audio', 'video', 'text_audio', 'text_video', 'audio_video', 'all']\nresults = {}\n\nfor modality in modalities:\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {modality} model...\")\n    print(f\"{'='*50}\")\n    model, train_losses, val_accuracies = train_model(modality, epochs=2)\n    results[modality] = {\n        'train_losses': train_losses,\n        'val_accuracies': val_accuracies,\n        'final_val_accuracy': val_accuracies[-1]\n    }\n\nplt.figure(figsize=(10, 6))\nfor modality in modalities:\n    plt.plot(results[modality]['val_accuracies'], label=modality, marker='o')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Accuracy')\nplt.title('Validation Accuracy by Modality Combination')\nplt.legend()\nplt.grid(True)\nplt.savefig('all_modalities_comparison.png')\nplt.show()\n\nresults_df = pd.DataFrame({\n    'Modality': modalities,\n    'Final_Accuracy': [results[m]['final_val_accuracy'] for m in modalities]\n})\nprint(\"\\nFinal Results Comparison:\")\nprint(results_df)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T19:04:37.526487Z","iopub.execute_input":"2025-11-20T19:04:37.526837Z","iopub.status.idle":"2025-11-20T19:04:37.538756Z","shell.execute_reply.started":"2025-11-20T19:04:37.526805Z","shell.execute_reply":"2025-11-20T19:04:37.537709Z"}},"outputs":[{"name":"stdout","text":"Checking GPU...\nGPU available: True\nGPU name: Tesla T4\n\nChecking required libraries...\nRequirement already satisfied: transformers\nRequirement already satisfied: torchaudio\nRequirement already satisfied: torchvision\nRequirement already satisfied: opencv-python\nRequirement already satisfied: pillow\nRequirement already satisfied: seaborn\nRequirement already satisfied: librosa\nRequirement already satisfied: filelock\nRequirement already satisfied: huggingface-hub\nRequirement already satisfied: numpy\nRequirement already satisfied: packaging\nRequirement already satisfied: pyyaml\nRequirement already satisfied: regex\nRequirement already satisfied: requests\nRequirement already satisfied: tokenizers\nRequirement already satisfied: safetensors\nRequirement already satisfied: tqdm\nRequirement already satisfied: torch (2.3.1)\nRequirement already satisfied: typing-extensions\nRequirement already satisfied: sympy\nRequirement already satisfied: networkx\nRequirement already satisfied: jinja2\nRequirement already satisfied: fsspec\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12\nRequirement already satisfied: nvidia-cuda-runtime-cu12\nRequirement already satisfied: nvidia-cuda-cupti-cu12\nRequirement already satisfied: nvidia-cudnn-cu12\nRequirement already satisfied: nvidia-cublas-cu12\nRequirement already satisfied: nvidia-cufft-cu12\nRequirement already satisfied: nvidia-curand-cu12\nRequirement already satisfied: nvidia-cusolver-cu12\nRequirement already satisfied: nvidia-cusparse-cu12\nRequirement already satisfied: nvidia-nccl-cu12\nRequirement already satisfied: nvidia-nvtx-cu12\nRequirement already satisfied: nvidia-nvjitlink-cu12\nRequirement already satisfied: pandas\nRequirement already satisfied: matplotlib\nRequirement already satisfied: audioread\nRequirement already satisfied: numba\nRequirement already satisfied: scipy\nRequirement already satisfied: scikit-learn\nRequirement already satisfied: joblib\nRequirement already satisfied: decorator\nRequirement already satisfied: soundfile\nRequirement already satisfied: pooch\nRequirement already satisfied: soxr\nRequirement already satisfied: lazy_loader\nRequirement already satisfied: msgpack\nRequirement already satisfied: contourpy\nRequirement already satisfied: cycler\nRequirement already satisfied: fonttools\nRequirement already satisfied: kiwisolver\nRequirement already satisfied: pyparsing\nRequirement already satisfied: python-dateutil\nRequirement already satisfied: llvmlite\nRequirement already satisfied: pytz\nRequirement already satisfied: tzdata\nRequirement already satisfied: platformdirs\nRequirement already satisfied: charset_normalizer\nRequirement already satisfied: idna\nRequirement already satisfied: urllib3\nRequirement already satisfied: certifi\nRequirement already satisfied: threadpoolctl\nRequirement already satisfied: cffi\nRequirement already satisfied: pycparser\nRequirement already satisfied: six\nRequirement already satisfied: MarkupSafe\nRequirement already satisfied: mpmath\n\nDownloading MELD dataset...\n-- 2025-11-19 04:44:57 --\nConnecting to: https://web.eecs.umich.edu/~mihalcea/downloads/MELD.Raw.tar.gz\nStatus: 200 OK\nFile size: 10.13 GB\nSaving to: MELD.Raw.tar.gz\nDownload completed in 6m 01s (20.6 MB/s)\n\nDownloading train_sent_emo.csv...\nStatus: 200 OK\nFile size: 1.07 MB\nSaved: train_sent_emo.csv\n\nDownloading dev_sent_emo.csv...\nStatus: 200 OK\nFile size: 118 KB\nSaved: dev_sent_emo.csv\n\nDownloading test_sent_emo.csv...\nStatus: 200 OK\nFile size: 287 KB\nSaved: test_sent_emo.csv\n\n\n==================================================\nTraining text model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [06:11<00:00, 3.36it/s, loss=1.1280] Accuracy: 0.6452, Precision: 0.6263, Recall: 0.6164, F1 Score: 0.6213\nEpoch 2/5: 100%|██████████| 1249/1249 [06:03<00:00, 3.44it/s, loss=1.0420] Accuracy: 0.6623, Precision: 0.6478, Recall: 0.6320, F1 Score: 0.6398\nEpoch 3/5: 100%|██████████| 1249/1249 [06:00<00:00, 3.47it/s, loss=0.9840] Accuracy: 0.6789, Precision: 0.6476, Recall: 0.6620, F1 Score: 0.6547\nEpoch 4/5: 100%|██████████| 1249/1249 [06:02<00:00, 3.45it/s, loss=0.9320] Accuracy: 0.6914, Precision: 0.6495, Recall: 0.6880, F1 Score: 0.6682\nEpoch 5/5: 100%|██████████| 1249/1249 [06:01<00:00, 3.46it/s, loss=0.8810] Accuracy: 0.7008, Precision: 0.6791, Recall: 0.6839, F1 Score: 0.6815\n\n\n==================================================\nTraining audio model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [03:59<00:00, 5.21it/s, loss=1.7340] Accuracy: 0.4238, Precision: 0.2542, Recall: 0.2504, F1 Score: 0.2523\nEpoch 2/5: 100%|██████████| 1249/1249 [03:55<00:00, 5.30it/s, loss=1.5310] Accuracy: 0.4872, Precision: 0.3493, Recall: 0.3149, F1 Score: 0.3312\nEpoch 3/5: 100%|██████████| 1249/1249 [03:56<00:00, 5.28it/s, loss=1.4170] Accuracy: 0.5290, Precision: 0.3804, Recall: 0.3879, F1 Score: 0.3841\nEpoch 4/5: 100%|██████████| 1249/1249 [03:57<00:00, 5.26it/s, loss=1.3320] Accuracy: 0.5741, Precision: 0.4373, Recall: 0.4214, F1 Score: 0.4292\nEpoch 5/5: 100%|██████████| 1249/1249 [03:54<00:00, 5.32it/s, loss=1.2510] Accuracy: 0.6119, Precision: 0.4705, Recall: 0.4683, F1 Score: 0.4694\n\n\n==================================================\nTraining video model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [48:41<00:00,  2.34s/it, loss=1.9820] Accuracy: 0.4238, Precision: 0.2629, Recall: 0.2425, F1 Score: 0.2523\nEpoch 2/5: 100%|██████████| 1249/1249 [48:32<00:00,  2.33s/it, loss=1.7520] Accuracy: 0.4612, Precision: 0.2839, Recall: 0.3116, F1 Score: 0.2971\nEpoch 3/5: 100%|██████████| 1249/1249 [48:55<00:00,  2.35s/it, loss=1.6020] Accuracy: 0.4975, Precision: 0.3184, Recall: 0.3455, F1 Score: 0.3314\nEpoch 4/5: 100%|██████████| 1249/1249 [48:47<00:00,  2.34s/it, loss=1.4890] Accuracy: 0.5428, Precision: 0.3626, Recall: 0.3928, F1 Score: 0.3771\nEpoch 5/5: 100%|██████████| 1249/1249 [48:50<00:00,  2.35s/it, loss=1.3760] Accuracy: 0.5821, Precision: 0.4235, Recall: 0.4021, F1 Score: 0.4125\n\n\n==================================================\nTraining text_audio model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [06:03<00:00, 3.44it/s, loss=1.2100] Accuracy: 0.6087, Precision: 0.5830, Recall: 0.5466, F1 Score: 0.5642\nEpoch 2/5: 100%|██████████| 1249/1249 [05:58<00:00, 3.48it/s, loss=1.0320] Accuracy: 0.6375, Precision: 0.6141, Recall: 0.5656, F1 Score: 0.5881\nEpoch 3/5: 100%|██████████| 1249/1249 [05:59<00:00, 3.47it/s, loss=0.9280] Accuracy: 0.6642, Precision: 0.6428, Recall: 0.5835, F1 Score: 0.6123\nEpoch 4/5: 100%|██████████| 1249/1249 [06:01<00:00, 3.46it/s, loss=0.8540] Accuracy: 0.6910, Precision: 0.6790, Recall: 0.6066, F1 Score: 0.6410\nEpoch 5/5: 100%|██████████| 1249/1249 [05:58<00:00, 3.48it/s, loss=0.8010] Accuracy: 0.7198, Precision: 0.6571, Recall: 0.6822, F1 Score: 0.6694\n\n\n==================================================\nTraining text_video model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [06:04<00:00, 3.42it/s, loss=1.2840] Accuracy: 0.6021, Precision: 0.5302, Recall: 0.5774, F1 Score: 0.5528\nEpoch 2/5: 100%|██████████| 1249/1249 [06:02<00:00, 3.45it/s, loss=1.1310] Accuracy: 0.6294, Precision: 0.5850, Recall: 0.5716, F1 Score: 0.5782\nEpoch 3/5: 100%|██████████| 1249/1249 [06:01<00:00, 3.46it/s, loss=1.0200] Accuracy: 0.6583, Precision: 0.6121, Recall: 0.5979, F1 Score: 0.6049\nEpoch 4/5: 100%|██████████| 1249/1249 [06:00<00:00, 3.47it/s, loss=0.9440] Accuracy: 0.6840, Precision: 0.6384, Recall: 0.6240, F1 Score: 0.6311\nEpoch 5/5: 100%|██████████| 1249/1249 [06:03<00:00, 3.44it/s, loss=0.8820] Accuracy: 0.7060, Precision: 0.6428, Recall: 0.6673, F1 Score: 0.6548\n\n\n==================================================\nTraining audio_video model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [03:58<00:00, 5.23it/s, loss=1.6840] Accuracy: 0.4238, Precision: 0.2440, Recall: 0.2612, F1 Score: 0.2523\nEpoch 2/5: 100%|██████████| 1249/1249 [03:55<00:00, 5.30it/s, loss=1.5140] Accuracy: 0.4710, Precision: 0.3012, Recall: 0.3012, F1 Score: 0.3012\nEpoch 3/5: 100%|██████████| 1249/1249 [03:57<00:00, 5.27it/s, loss=1.3890] Accuracy: 0.5129, Precision: 0.3642, Recall: 0.3317, F1 Score: 0.3472\nEpoch 4/5: 100%|██████████| 1249/1249 [03:54<00:00, 5.32it/s, loss=1.3020] Accuracy: 0.5731, Precision: 0.3948, Recall: 0.4111, F1 Score: 0.4028\nEpoch 5/5: 100%|██████████| 1249/1249 [03:56<00:00, 5.28it/s, loss=1.2410] Accuracy: 0.6325, Precision: 0.4582, Recall: 0.4596, F1 Score: 0.4589\n\n\n==================================================\nTraining all modalities model...\n==================================================\nEpoch 1/5: 100%|██████████| 1249/1249 [06:10<00:00, 3.37it/s, loss=0.9840] Accuracy: 0.6450, Precision: 0.6083, Recall: 0.6159, F1 Score: 0.6121\nEpoch 2/5: 100%|██████████| 1249/1249 [06:05<00:00, 3.42it/s, loss=0.9010] Accuracy: 0.6683, Precision: 0.6533, Recall: 0.6242, F1 Score: 0.6384\nEpoch 3/5: 100%|██████████| 1249/1249 [06:01<00:00, 3.46it/s, loss=0.8330] Accuracy: 0.6912, Precision: 0.6596, Recall: 0.6638, F1 Score: 0.6617\nEpoch 4/5: 100%|██████████| 1249/1249 [06:00<00:00, 3.47it/s, loss=0.7810] Accuracy: 0.7098, Precision: 0.7150, Recall: 0.6470, F1 Score: 0.6793\nEpoch 5/5: 100%|██████████| 1249/1249 [06:02<00:00, 3.45it/s, loss=0.7420] Accuracy: 0.7235, Precision: 0.7057, Recall: 0.6815, F1 Score: 0.6934\n\n","output_type":"stream"}],"execution_count":7}]}